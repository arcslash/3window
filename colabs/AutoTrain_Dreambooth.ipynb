{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "outputId": "f4e698aa-ff13-4d34-bb0f-7135dbdfdf29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'ishara_gan' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'photo of ishara' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"isharaux/ishara-gan\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "gradient_checkpointing = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "outputId": "bbeb49e6-db56-482c-bebe-a9ec14c34dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Namespace(version=False, model='stabilityai/stable-diffusion-xl-base-1.0', revision=None, tokenizer=None, image_path='images/', class_image_path=None, prompt='photo of ishara', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, project_name='ishara_gan', seed=42, resolution=1024, center_crop=None, train_text_encoder=None, batch_size=1, sample_batch_size=4, epochs=1, num_steps=500, checkpointing_steps=100000, resume_from_checkpoint=None, gradient_accumulation=4, gradient_checkpointing=True, lr=0.0001, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=True, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=True, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, fp16=True, bf16=None, token='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', repo_id='isharaux/ishara-gan', push_to_hub=True, validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, username=None, func=<function run_dreambooth_command_factory at 0x7823cd3f89d0>)\u001b[0m\n",
            "> \u001b[1mINFO    Running DreamBooth Training\u001b[0m\n",
            "> \u001b[33m\u001b[1mWARNING Parameters supplied but not used: version, func\u001b[0m\n",
            "Downloading (â€¦)okenizer_config.json: 100% 737/737 [00:00<00:00, 3.21MB/s]\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.27MB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 3.91MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 1.97MB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 725/725 [00:00<00:00, 2.85MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.08MB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 565/565 [00:00<00:00, 2.60MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading (â€¦)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 2.59MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading model.safetensors: 100% 492M/492M [00:03<00:00, 157MB/s]\n",
            "Downloading model.safetensors: 100% 2.78G/2.78G [00:13<00:00, 212MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 642/642 [00:00<00:00, 3.60MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 232MB/s]\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 7.68MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 10.3G/10.3G [01:13<00:00, 139MB/s]\n",
            "{'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)cheduler_config.json: 100% 479/479 [00:00<00:00, 1.96MB/s]\n",
            "{'dynamic_thresholding_ratio', 'clip_sample_range', 'thresholding', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "> \u001b[1mINFO    Enabling xformers\u001b[0m\n",
            "> \u001b[1mINFO    Enabling gradient checkpointing.\u001b[0m\n",
            "> \u001b[1mINFO    Computing text embeddings for prompt: photo of ishara\u001b[0m\n",
            "> \u001b[1mINFO    ***** Running training *****\u001b[0m\n",
            "> \u001b[1mINFO      Num examples = 35\u001b[0m\n",
            "> \u001b[1mINFO      Num batches each epoch = 35\u001b[0m\n",
            "> \u001b[1mINFO      Num Epochs = 56\u001b[0m\n",
            "> \u001b[1mINFO      Instantaneous batch size per device = 1\u001b[0m\n",
            "> \u001b[1mINFO      Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "> \u001b[1mINFO      Gradient Accumulation steps = 4\u001b[0m\n",
            "> \u001b[1mINFO      Total optimization steps = 500\u001b[0m\n",
            "> \u001b[1mINFO      Training config = {'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'revision': None, 'tokenizer': None, 'image_path': 'images/', 'class_image_path': None, 'prompt': 'photo of ishara', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'ishara_gan', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 56, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'gradient_checkpointing': True, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': True, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'fp16': True, 'bf16': False, 'token': '*****', 'repo_id': 'isharaux/ishara-gan', 'push_to_hub': True, 'username': None, 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "Steps:   0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:1470: FutureWarning: `LoRAAttnProcessor2_0` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor2_0 instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
            "  deprecate(\n",
            "Steps:  96% 480/500 [1:55:30<04:48, 14.45s/it, loss=0.0181, lr=0.0001]"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_LvIS7-7PcLT",
        "outputId": "4b3d8893-36ce-4aaa-984b-cf261f44558a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b6b6c194b81e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiffusionPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStableDiffusionXLImg2ImgPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Inference\n",
        "# this is the inference code that you can use after you have trained your model\n",
        "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
        "#\n",
        "#\n",
        "#\n",
        "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "prj_path = \"isharaux/ishara-gan\"\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "prompt = \"photo of ishara wearing a suite\"\n",
        "\n",
        "seed = 42\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "image.save(f\"generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}